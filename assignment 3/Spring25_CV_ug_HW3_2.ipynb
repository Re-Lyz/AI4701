{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3-2: MNIST 手写数字识别 （80分）\n",
    "\n",
    "- 本次作业的主题是使用深度学习技术对`MNIST`手写数字数据集进行分类。\n",
    "- 要求使用两种不同的深度学习模型，分别是多层感知机--`MLP`和卷积神经网络--`CNN`。\n",
    "- 本次作业的目的是让同学们了解深度学习模型的构建和训练过程，以及对经典视觉任务处理效果的对比。\n",
    "\n",
    "## 评分标准（更细致的评分标准见对应部分）\n",
    "\n",
    "- 数据读取和预处理：5分\n",
    "- 基于`MLP`的手写数字分类：30分 \n",
    "- 基于`CNN`的手写数字分类：30分\n",
    "- 结果讨论与对比分析：15分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 第一部分：数据读取和预处理\n",
    "\n",
    "你可以在Canvas上下载如下两个文件：\n",
    "- 训练数据：`mnist_train.csv`\n",
    "- 测试数据：`mnist_test.csv`\n",
    "\n",
    "这两个文件包含了Mnist数据集的训练集和测试集。每一行的第一个数字表示标签，后面的784数字是28x28的图片像素值。\n",
    "- 请你正确读取并分别展示训练集和测试集的第一个样本（图像+label）。\n",
    "\n",
    "### 评分细则\n",
    "- 数据读取：2分\n",
    "- 数据展示：3分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df = pd.read_csv('mnist_train.csv')\n",
    "test_df = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "train_df.head()\n",
    "test_df.head()\n",
    "\n",
    "labels = train_df.iloc[:, 0].values\n",
    "pixels = train_df.iloc[:, 1:].values\n",
    "images = pixels.reshape(-1, 28, 28)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(f'Label: {labels[i]}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第二部分：基于`MLP`的手写数字分类\n",
    "\n",
    "- 请你构建一个多层感知机模型，在Mnist数据集上进行训练和测试。\n",
    "- 可以使用`Pytorch`或者`Tensorflow`等深度学习框架。\n",
    "- 请你展示模型的训练过程（Loss曲线）和测试结果（分类精度）。\n",
    "\n",
    "### 评分细则\n",
    "- 模型构建：10分\n",
    "- 模型训练：10分 - 要求Loss曲线收敛\n",
    "- 模型测试：10分 - 要求分类精度达到90%以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 844/844 [00:00<00:00, 979.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Loss: 0.3582 — Accuracy: 90.90%\n",
      "Validation Loss: 0.0768 — Validation Accuracy: 91.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 844/844 [00:00<00:00, 993.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 — Loss: 0.1493 — Accuracy: 95.51%\n",
      "Validation Loss: 0.0786 — Validation Accuracy: 95.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 844/844 [00:00<00:00, 974.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 — Loss: 0.1148 — Accuracy: 96.51%\n",
      "Validation Loss: 0.0364 — Validation Accuracy: 96.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 844/844 [00:00<00:00, 905.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 — Loss: 0.1006 — Accuracy: 96.91%\n",
      "Validation Loss: 0.0815 — Validation Accuracy: 96.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 844/844 [00:00<00:00, 933.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 — Loss: 0.0900 — Accuracy: 97.33%\n",
      "Validation Loss: 0.0310 — Validation Accuracy: 97.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 844/844 [00:00<00:00, 920.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 — Loss: 0.0801 — Accuracy: 97.61%\n",
      "Validation Loss: 0.0981 — Validation Accuracy: 97.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 844/844 [00:00<00:00, 926.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 — Loss: 0.0732 — Accuracy: 97.78%\n",
      "Validation Loss: 0.1206 — Validation Accuracy: 97.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 844/844 [00:00<00:00, 936.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 — Loss: 0.0721 — Accuracy: 97.86%\n",
      "Validation Loss: 0.0535 — Validation Accuracy: 97.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 844/844 [00:00<00:00, 945.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 — Loss: 0.0625 — Accuracy: 98.14%\n",
      "Validation Loss: 0.0441 — Validation Accuracy: 97.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 844/844 [00:00<00:00, 950.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 — Loss: 0.0638 — Accuracy: 98.10%\n",
      "Validation Loss: 0.0336 — Validation Accuracy: 97.97%\n",
      "test Accuracy: 96.92%\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)  # 28*28=784\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 classes for digits 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Convert DataFrame to PyTorch tensors\n",
    "def df_to_tensor(df):\n",
    "    labels   = torch.as_tensor(df.iloc[:, 0].values, dtype=torch.long)\n",
    "    features = torch.as_tensor(df.iloc[:, 1:].values, dtype=torch.float32)\n",
    "    return features, labels\n",
    "\n",
    "model=SimpleNN()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_features, train_labels = df_to_tensor(train_df)\n",
    "\n",
    "train_features = train_features.to(device)\n",
    "train_labels   = train_labels.to(device)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def train_model(model, train_loader,val_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct     = 0\n",
    "        total       = 0\n",
    "        \n",
    "        for features, labels in tqdm.tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(features)                   \n",
    "            loss    = criterion(outputs, labels)        \n",
    "            loss.backward()                            \n",
    "            optimizer.step()                            \n",
    "\n",
    "            batch_size     = labels.size(0)\n",
    "            running_loss  += loss.item() * batch_size\n",
    "            \n",
    "            preds          = outputs.argmax(dim=1)\n",
    "            correct      += (preds == labels).sum().item()\n",
    "            total        += batch_size\n",
    "        \n",
    "        # 计算 epoch 平均损失和准确率\n",
    "        epoch_loss = running_loss / total\n",
    "        accuracy   = 100 * correct / total\n",
    "        \n",
    "        print(\n",
    "            f'Epoch {epoch+1}/{epochs} — '\n",
    "            f'Loss: {epoch_loss:.4f} — '\n",
    "            f'Accuracy: {accuracy:.2f}%'\n",
    "        )\n",
    "        \n",
    "        for features, labels in val_loader:\n",
    "            model.eval()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        print(f'Validation Loss: {loss.item():.4f} — Validation Accuracy: {100 * correct / total:.2f}%')\n",
    "            \n",
    "\n",
    "test_features, test_labels = df_to_tensor(test_df)\n",
    "test_features = test_features.to(device)\n",
    "test_labels   = test_labels.to(device)        \n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "train_model(model, train_loader,val_loader, criterion, optimizer, epochs=10)\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备：cuda\n",
      "unseen_1.jpg  |  gt: unseen_1  |  pred_idx: 3\n",
      "unseen_4.jpg  |  gt: unseen_4  |  pred_idx: 9\n",
      "unseen_5.jpg  |  gt: unseen_5  |  pred_idx: 5\n",
      "unseen_7.jpg  |  gt: unseen_7  |  pred_idx: 1\n",
      "unseen_9.jpg  |  gt: unseen_9  |  pred_idx: 8\n",
      "评估结束。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_to_tensor(image_path, device):\n",
    "    img = Image.open(image_path).convert(\"L\")\n",
    "    byte_tensor = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    hw_tensor = byte_tensor.view(img.size[1], img.size[0]).float()  # 转换为 float32\n",
    "    return hw_tensor.to(device)\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_dir   =\"unseen\" \n",
    "    if not os.path.isdir(data_dir):\n",
    "        print(f\"[Error] 指定的图片文件夹不存在：{data_dir}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"使用设备：{device}\")\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\"}\n",
    "    image_paths = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        ext = os.path.splitext(fname)[1].lower()\n",
    "        if ext in exts:\n",
    "            image_paths.append(os.path.join(data_dir, fname))\n",
    "    image_paths.sort()\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"[Error] 目录 {data_dir} 下没有找到任何图片文件。\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_path in image_paths:\n",
    "            filename = os.path.basename(img_path)\n",
    "            gt_label = os.path.splitext(filename)[0]  # 去掉扩展名作为真实标签\n",
    "\n",
    "            input_tensor = load_image_to_tensor(img_path, device)  # (1, 1, H, W)\n",
    "            input_tensor = input_tensor.view(1,-1)  # 展平为 (1, 784)\n",
    "            \n",
    "            outputs = model(input_tensor)  # 假设 outputs.shape = (1, num_classes)\n",
    "            pred_idx = torch.argmax(outputs).item()\n",
    "\n",
    "            # 6.3 直接打印当前图片的结果\n",
    "            print(f\"{filename}  |  gt: {gt_label}  |  pred_idx: {pred_idx}\")\n",
    "\n",
    "    print(\"评估结束。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第三部分：基于`CNN`的手写数字分类\n",
    "\n",
    "- 请你构建一个卷积神经网络模型，在Mnist数据集上进行训练和测试。\n",
    "- 可以使用`Pytorch`或者`Tensorflow`等深度学习框架。\n",
    "- 请你展示模型的训练过程（Loss曲线）和测试结果（分类精度）。\n",
    "\n",
    "### 评分细则\n",
    "- 模型构建：10分\n",
    "- 模型训练：10分 - 要求Loss曲线收敛\n",
    "- 模型测试：10分 - 要求分类精度达到95%以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 844/844 [00:01<00:00, 599.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 — Loss: 0.3410 — Accuracy: 94.67%\n",
      "Validation Loss: 0.0209 — Validation Accuracy: 94.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 844/844 [00:01<00:00, 723.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 — Loss: 0.0620 — Accuracy: 97.97%\n",
      "Validation Loss: 0.0062 — Validation Accuracy: 97.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 844/844 [00:01<00:00, 677.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 — Loss: 0.0428 — Accuracy: 98.69%\n",
      "Validation Loss: 0.0975 — Validation Accuracy: 98.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 844/844 [00:01<00:00, 732.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 — Loss: 0.0370 — Accuracy: 98.79%\n",
      "Validation Loss: 0.0074 — Validation Accuracy: 98.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 844/844 [00:01<00:00, 710.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 — Loss: 0.0299 — Accuracy: 99.04%\n",
      "Validation Loss: 0.0578 — Validation Accuracy: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 844/844 [00:01<00:00, 715.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 — Loss: 0.0251 — Accuracy: 99.22%\n",
      "Validation Loss: 0.0001 — Validation Accuracy: 99.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 844/844 [00:01<00:00, 714.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 — Loss: 0.0250 — Accuracy: 99.17%\n",
      "Validation Loss: 0.0084 — Validation Accuracy: 99.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 844/844 [00:01<00:00, 719.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 — Loss: 0.0205 — Accuracy: 99.34%\n",
      "Validation Loss: 0.0536 — Validation Accuracy: 99.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 844/844 [00:01<00:00, 731.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 — Loss: 0.0184 — Accuracy: 99.43%\n",
      "Validation Loss: 0.0778 — Validation Accuracy: 99.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 844/844 [00:01<00:00, 745.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 — Loss: 0.0200 — Accuracy: 99.38%\n",
      "Validation Loss: 0.1853 — Validation Accuracy: 99.28%\n",
      "test Accuracy: 98.43%\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 28x28 -> 28x28\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # 7x7 after pooling\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)  # 28x28 -> 14x14\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, kernel_size=2)  # 14x14 -> 7x7\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_features, train_labels = df_to_tensor(train_df)\n",
    "train_features = train_features.view(-1, 1, 28, 28).to(device)  # Reshape for CNN\n",
    "train_labels = train_labels.to(device)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, random_state=42)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_features, test_labels = df_to_tensor(test_df)\n",
    "test_features = test_features.view(-1, 1, 28, 28).to(device)  # Reshape for CNN\n",
    "test_labels = test_labels.to(device)\n",
    "test_dataset = torch.utils.data.TensorDataset(test_features, test_labels)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_model(model, train_loader,val_loader, criterion, optimizer, epochs=10)\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备：cuda\n",
      "开始评估，共 5 张图片。\n",
      "unseen_1.jpg  |  gt: unseen_1  |  pred_idx: 1\n",
      "unseen_4.jpg  |  gt: unseen_4  |  pred_idx: 4\n",
      "unseen_5.jpg  |  gt: unseen_5  |  pred_idx: 5\n",
      "unseen_7.jpg  |  gt: unseen_7  |  pred_idx: 7\n",
      "unseen_9.jpg  |  gt: unseen_9  |  pred_idx: 9\n",
      "评估结束。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    data_dir   =\"unseen\" \n",
    "    if not os.path.isdir(data_dir):\n",
    "        print(f\"[Error] 指定的图片文件夹不存在：{data_dir}\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"使用设备：{device}\")\n",
    "    model.eval()\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\"}\n",
    "    image_paths = []\n",
    "    for fname in os.listdir(data_dir):\n",
    "        ext = os.path.splitext(fname)[1].lower()\n",
    "        if ext in exts:\n",
    "            image_paths.append(os.path.join(data_dir, fname))\n",
    "    image_paths.sort()\n",
    "\n",
    "    if len(image_paths) == 0:\n",
    "        print(f\"[Error] 目录 {data_dir} 下没有找到任何图片文件。\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"开始评估，共 {len(image_paths)} 张图片。\")\n",
    "    with torch.no_grad():\n",
    "        for img_path in image_paths:\n",
    "            filename = os.path.basename(img_path)\n",
    "            gt_label = os.path.splitext(filename)[0]  # 去掉扩展名作为真实标签\n",
    "\n",
    "            input_tensor = load_image_to_tensor(img_path, device)  \n",
    "            input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)\n",
    "                \n",
    "            outputs = model(input_tensor)  # 假设 outputs.shape = (1, num_classes)\n",
    "            pred_idx = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "            # 6.3 直接打印当前图片的结果\n",
    "            print(f\"{filename}  |  gt: {gt_label}  |  pred_idx: {pred_idx}\")\n",
    "\n",
    "    print(\"评估结束。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 第四部分：结果讨论与对比分析\n",
    "\n",
    "- 请你对`MLP`和`CNN`两种模型的训练和测试结果进行对比分析。\n",
    "- 你可以从模型的训练速度、模型的性能、模型的泛化能力等方面进行分析。\n",
    "    - 训练速度：模型训练所需的时间\n",
    "    - 模型性能：模型在测试集上的分类精度\n",
    "    - 模型泛化能力：模型在未知数据上的表现，未知数据可以从Canvas上下载，在文件夹`unseen`中有5张手写数字图片。\n",
    "- 请在下面的markdown cell中写下你的分析结果。\n",
    "\n",
    "### 评分细则\n",
    "- 结果讨论与对比分析：\n",
    "    - 训练速度：4分\n",
    "    - 模型性能：4分\n",
    "    - 模型泛化能力：5分\n",
    "    - 其他：2分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 评估维度                    | MLP                                                                   | CNN                                                                    | 结论                                                   |\n",
    "| ----------------------- | --------------------------------------------------------------------- | ---------------------------------------------------------------------- | ---------------------------------------------------- |\n",
    "| **训练速度**                | - **首轮** ≈ 0.86 s（979 it/s）<br>- 其后约 0.9 s/epoch（920 – 950 it/s）      | - **首轮** ≈ 1.41 s（600 it/s）<br>- 其后约 1.1 – 1.2 s/epoch（680 – 745 it/s） | MLP 约 **25 – 30 %** 更快：全连接层参数少、计算密集度低；CNN 的卷积核计算更耗时。 |\n",
    "| **模型性能**<br>(测试集)       | **96.92 %**                                                           | **98.43 %**                                                            | CNN 高出 **1.51 pp**。卷积层可提取局部空间特征，对手写数字尤其有效。           |\n",
    "| **训练-验证差异**             | - 末轮训练 98.10 % vs 验证 97.97 %<br>- 差值 **0.13 pp**<br>- 验证损失整体稳定，偶有小幅波动 | - 末轮训练 99.38 % vs 验证 99.28 %<br>- 差值 **0.10 pp**<br>- 验证损失偶尔抬头，但幅度更小   | 两者过拟合都轻微，CNN 仍略占优势。                                  |\n",
    "| **泛化能力**<br>(unseen 数据) | 5 张未知样本仅预测对 **1/5**（20 %）；对噪声、位置变换更敏感                                 | 5 张全部预测正确 **5/5**（100 %）；卷积的平移不变性带来更强鲁棒性                               | CNN 显著优于 MLP，在真实未知数据上表现更稳健。                          |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
